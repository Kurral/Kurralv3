# How to Perform Replay

This guide explains how to replay artifacts generated by your agents.

## Quick Start

### Method 1: Using the replay module (Recommended)

```bash
# From the agent directory
python -m kurral.replay <kurral_id>
```

**Example:**
```bash
cd my_agent
python -m kurral.replay 961061f9-8029-4949-a07e-11a028d75cc4
```

### Method 2: Using replay_cmd with file path

```bash
# From the agent directory
python -m kurral.cli.replay_cmd artifacts/<artifact_file>.kurral
```

**Example:**
```bash
cd my_agent
python -m kurral.cli.replay_cmd artifacts/961061f9-8029-4949-a07e-11a028d75cc4.kurral --verbose
```

## Command Options

### Replay by artifact file path
```bash
# From agent directory
python -m kurral.replay 961061f9-8029-4949-a07e-11a028d75cc4

# Or using replay_cmd with file path
python -m kurral.cli.replay_cmd artifacts/961061f9-8029-4949-a07e-11a028d75cc4.kurral
```

### Replay by run_id
```bash
python -m kurral.replay --run-id local_run_graph_with_kurral_1763472818 --artifacts-dir artifacts
```

### Replay latest artifact
```bash
python -m kurral.replay --latest --artifacts-dir artifacts
```

### Replay with different LLM (B replay)
```bash
# Requires OPENAI_API_KEY or ANTHROPIC_API_KEY environment variable
python -m kurral.cli.replay_cmd artifacts/961061f9-8029-4949-a07e-11a028d75cc4.kurral --llm-client openai
```

### Replay with different model
```bash
python -m kurral.cli.replay_cmd artifacts/961061f9-8029-4949-a07e-11a028d75cc4.kurral --current-model gpt-4-turbo
```

### Show diff between original and replay
```bash
python -m kurral.cli.replay_cmd artifacts/961061f9-8029-4949-a07e-11a028d75cc4.kurral --diff
```

### Verbose output
```bash
python -m kurral.cli.replay_cmd artifacts/961061f9-8029-4949-a07e-11a028d75cc4.kurral --verbose
```

## Understanding Replay Types

### A Replay (Deterministic)
- **When**: Determinism score < 0.8 AND no changes detected
- **What happens**: Returns outputs directly from the artifact (no LLM execution, no tool execution)
- **Use case**: When everything is identical to the original run
- **Cost**: Zero API costs

### B Replay (Non-deterministic)
- **When**: Determinism score >= 0.8 OR changes detected (LLM model, parameters, tools, prompt, graph)
- **What happens**: Re-executes the LLM but uses cached tool calls via semantic matching (85% threshold)
- **Use case**: When you want to test a different LLM with the same tool inputs
- **Cost**: Reduced API costs via semantic tool caching

## Finding Artifacts

Artifacts are stored in each agent's `artifacts/` folder:

- `agent1/artifacts/` - Artifacts from agent1
- `agent2/artifacts/` - Artifacts from agent2 (if you have one)
- etc.

Each artifact file is named with its `kurral_id` (UUID):
```
agent1/artifacts/961061f9-8029-4949-a07e-11a028d75cc4.kurral
```

An `index.json` file in each artifacts folder contains metadata about all artifacts.

## Example Output

```
Replaying artifact: 961061f9-8029-4949-a07e-11a028d75cc4
Original run: local_run_graph_with_kurral_1763472818

Replay Type: A
Determinism Score: 0.82 (threshold: 0.80)
No changes detected

+----------------+
| Replay Outputs |
+----------------+
{
  "question": "What is the capital of france",
  "output": "...",
  ...
}

[SUCCESS] Replay completed in 0ms
Replay type: A
Cache hits: 2
Cache misses: 0
Hash match: [SUCCESS] (118c0161 -> 118c0161)
Structural match: [SUCCESS]
[SUCCESS] Outputs match original
```

## Troubleshooting

### Error: "Must provide artifact, --run-id, or --latest"
Make sure you're providing one of:
- Artifact file path as first argument
- `--run-id <run_id>` option
- `--latest` flag

### Error: "OPENAI_API_KEY not set (required for B replay)"
For B replays, you need to set the appropriate API key:
```bash
# Windows PowerShell
$env:OPENAI_API_KEY="your-key-here"

# Or create/update .env file in agent folder
```

### Artifact not found
- Check that the artifact ID or path is correct
- Make sure you're running from the agent directory (where `artifacts/` folder exists)
- Use `--artifacts-dir` to specify a different artifacts directory
- If using R2, verify R2 credentials are set correctly

